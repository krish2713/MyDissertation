{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KHvrpQuTSENa"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import hashlib\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_concatted = pd.read_csv(\"/content/drive/MyDrive/ieeecis/train_concatted_v2.csv\")\n",
        "num_trans_cols = pd.read_csv(\"/content/drive/MyDrive/ieeecis/num_trans_cols_v2.csv\", header=None).iloc[:, 0].tolist()"
      ],
      "metadata": {
        "id": "u82CgeFjztoD"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate normal & fraudulent samples\n",
        "X_normal = train_concatted[train_concatted['isFraud'] == 0]  # Normal transactions\n",
        "X_anomaly = train_concatted[train_concatted['isFraud'] == 1]  # Fraudulent transactions (for evaluation)\n",
        "\n",
        "print(f\"Train shape: {X_normal.shape}, Test shape: {X_anomaly.shape}\")\n",
        "\n",
        "# Drop TransactionID and target variable from train dataset for preprocessing\n",
        "# train_target = train_transaction[\"isFraud\"]\n",
        "X_normal.drop(columns=[\"TransactionID\", \"isFraud\"], inplace=True)\n",
        "X_anomaly.drop(columns=[\"TransactionID\",\"isFraud\"], inplace=True)\n",
        "# X_normal.drop(columns=[\"isFraud\"], inplace=True)\n",
        "# X_anomaly.drop(columns=[\"isFraud\"], inplace=True)\n",
        "\n",
        "num_trans_cols.remove(\"TransactionID\")\n",
        "\n",
        "# Normalize numerical features using StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_normal[num_trans_cols] = scaler.fit_transform(X_normal[num_trans_cols])\n",
        "X_anomaly[num_trans_cols] = scaler.transform(X_anomaly[num_trans_cols])\n",
        "\n",
        "\n",
        "# Convert data types to reduce memory usage\n",
        "def reduce_memory(df):\n",
        "    for col in df.columns:\n",
        "        if df[col].dtype == \"float64\":\n",
        "            df[col] = df[col].astype(\"float32\")\n",
        "        elif df[col].dtype == \"int64\":\n",
        "            df[col] = df[col].astype(\"int32\")\n",
        "    return df\n",
        "\n",
        "#train_df = reduce_memory(train_df)\n",
        "#test_df = reduce_memory(test_df)\n",
        "# Final processed datasets\n",
        "print(f\"Train shape: {X_normal.shape}, Test shape: {X_anomaly.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6NLg8U9_FIy",
        "outputId": "6b1f8cc5-f447-4b9f-f7a2-2cc21f4aad9d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shape: (569877, 252), Test shape: (20663, 252)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-1c8cff8eda03>:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X_normal.drop(columns=[\"TransactionID\", \"isFraud\"], inplace=True)\n",
            "<ipython-input-3-1c8cff8eda03>:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X_anomaly.drop(columns=[\"TransactionID\",\"isFraud\"], inplace=True)\n",
            "<ipython-input-3-1c8cff8eda03>:18: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X_normal[num_trans_cols] = scaler.fit_transform(X_normal[num_trans_cols])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shape: (569877, 250), Test shape: (20663, 250)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-1c8cff8eda03>:19: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X_anomaly[num_trans_cols] = scaler.transform(X_anomaly[num_trans_cols])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "batch_size = 4096\n",
        "X_train, X_test_normal = train_test_split(X_normal, test_size=0.01, random_state=42)\n",
        "X_normal_tensor = torch.tensor(X_train.values.astype(np.float32), dtype=torch.float32)\n",
        "train_loader = torch.utils.data.DataLoader(X_normal_tensor, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "Y6T3ydDdei3-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import numpy as np\n",
        "import torch.nn.utils.parametrizations as param\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "\n",
        "# PyTorch Generator Model\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, latent_dim, output_dim):\n",
        "        super(Generator, self).__init__()\n",
        "        self.fc1 = nn.Linear(latent_dim, 128)\n",
        "        self.fc2 = nn.Linear(128, 256)\n",
        "        self.fc3 = nn.Linear(256, output_dim)\n",
        "\n",
        "        # Xavier initialization (equivalent to TensorFlow's `init_kernel`)\n",
        "        nn.init.xavier_uniform_(self.fc1.weight)\n",
        "        nn.init.xavier_uniform_(self.fc2.weight)\n",
        "        nn.init.xavier_uniform_(self.fc3.weight)\n",
        "\n",
        "    def forward(self, z):\n",
        "        z = F.relu(self.fc1(z))\n",
        "        z = F.relu(self.fc2(z))\n",
        "        output = self.fc3(z)  # Last layer (no activation)\n",
        "        return output\n",
        "\n",
        "# PyTorch Encoder Model\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, latent_dim):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, latent_dim)\n",
        "\n",
        "        # Xavier initialization (equivalent to TensorFlow's `init_kernel`)\n",
        "        nn.init.xavier_uniform_(self.fc1.weight)\n",
        "        nn.init.xavier_uniform_(self.fc2.weight)\n",
        "        nn.init.xavier_uniform_(self.fc3.weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.leaky_relu(self.fc1(x),negative_slope=0.2)\n",
        "        x = F.leaky_relu(self.fc2(x),negative_slope=0.2)\n",
        "        x = self.fc3(x)  # Last layer (latent space) has no activation\n",
        "        return x\n",
        "\n",
        "# Define Discriminator Dxz\n",
        "class DiscriminatorXZ(nn.Module):\n",
        "    def __init__(self, x_dim, z_dim, do_spectral_norm=False):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x_dim (int): Dimensionality of the x input.\n",
        "            z_dim (int): Dimensionality of the z input.\n",
        "            do_spectral_norm (bool): If True, apply spectral normalization to linear layers.\n",
        "        \"\"\"\n",
        "        super(DiscriminatorXZ, self).__init__()\n",
        "\n",
        "        # Helper: apply spectral normalization if desired\n",
        "        sn = torch.nn.utils.spectral_norm if do_spectral_norm else lambda layer: layer\n",
        "\n",
        "        # D(x) branch: dense layer -> batch norm -> leaky ReLU\n",
        "        self.x_fc1 = sn(nn.Linear(x_dim, 128))\n",
        "        self.x_bn1 = nn.BatchNorm1d(128)\n",
        "\n",
        "        # D(z) branch: dense layer -> leaky ReLU -> dropout\n",
        "        self.z_fc1 = sn(nn.Linear(z_dim, 128))\n",
        "        self.dropout = nn.Dropout(0.5)  # dropout rate 0.5\n",
        "\n",
        "        # Combined branch (D(x,z)): after concatenation of x and z branches\n",
        "        self.y_fc1 = sn(nn.Linear(128 + 128, 256))  # concatenated size = 256\n",
        "        self.y_fc2 = sn(nn.Linear(256, 1))  # output logits\n",
        "\n",
        "        # Xavier (Glorot) initialization for all linear layers\n",
        "        nn.init.xavier_uniform_(self.x_fc1.weight)\n",
        "        nn.init.xavier_uniform_(self.z_fc1.weight)\n",
        "        nn.init.xavier_uniform_(self.y_fc1.weight)\n",
        "        nn.init.xavier_uniform_(self.y_fc2.weight)\n",
        "\n",
        "    def forward(self, x, z):\n",
        "        # D(x) branch:\n",
        "        x_out = self.x_fc1(x)\n",
        "        x_out = self.x_bn1(x_out)\n",
        "        x_out = F.leaky_relu(x_out,negative_slope=0.2)\n",
        "\n",
        "        # D(z) branch:\n",
        "        z_out = self.z_fc1(z)\n",
        "        z_out = F.leaky_relu(z_out,negative_slope=0.2)\n",
        "        z_out = self.dropout(z_out)  # dropout is active only in training mode\n",
        "\n",
        "        # Concatenate the branches along the feature dimension\n",
        "        y = torch.cat([x_out, z_out], dim=1)\n",
        "\n",
        "        # Combined branch:\n",
        "        y = self.y_fc1(y)\n",
        "        y = F.leaky_relu(y,negative_slope=0.2)\n",
        "        y = self.dropout(y)\n",
        "\n",
        "        intermediate_layer = y  # For feature matching\n",
        "\n",
        "        # Final logits layer (no activation)\n",
        "        logits = self.y_fc2(y)\n",
        "\n",
        "        return logits, intermediate_layer\n",
        "\n",
        "\n",
        "# Define Discriminator Dxx\n",
        "class DiscriminatorXX(nn.Module):\n",
        "    def __init__(self, input_dim, do_spectral_norm=False):\n",
        "        super(DiscriminatorXX, self).__init__()\n",
        "\n",
        "        # Apply spectral normalization if enabled\n",
        "        spectral_layer = torch.nn.utils.spectral_norm if do_spectral_norm else lambda x: x\n",
        "\n",
        "        # Fully connected layers with Spectral Normalization\n",
        "        self.fc1 = spectral_layer(nn.Linear(input_dim * 2, 256))\n",
        "        self.fc2 = spectral_layer(nn.Linear(256, 128))\n",
        "        self.fc3 = spectral_layer(nn.Linear(128, 1))  # Final output layer\n",
        "\n",
        "        self.dropout = nn.Dropout(0.2)  # Dropout layer\n",
        "\n",
        "        # Xavier Initialization (equivalent to TensorFlow's `init_kernel`)\n",
        "        nn.init.xavier_uniform_(self.fc1.weight)\n",
        "        nn.init.xavier_uniform_(self.fc2.weight)\n",
        "        nn.init.xavier_uniform_(self.fc3.weight)\n",
        "\n",
        "    def forward(self, x, rec_x):\n",
        "        # Concatenate x and rec_x\n",
        "        net = torch.cat([x, rec_x], dim=1)\n",
        "\n",
        "        # Layer 1\n",
        "        net = F.leaky_relu(self.fc1(net),negative_slope=0.2)\n",
        "        net = self.dropout(net) if self.training else net  # Dropout only during training\n",
        "\n",
        "        # Layer 2\n",
        "        net = F.leaky_relu(self.fc2(net),negative_slope=0.2)\n",
        "        net = self.dropout(net) if self.training else net  # Dropout only during training\n",
        "        intermediate_layer = net\n",
        "\n",
        "        # # Layer 3 (Logits)\n",
        "        logits = self.fc3(net)  # No activation in final layer\n",
        "\n",
        "        return logits, intermediate_layer\n",
        "\n",
        "# Define Discriminator Dzz\n",
        "class DiscriminatorZZ(nn.Module):\n",
        "    def __init__(self, latent_dim, do_spectral_norm=False):\n",
        "        super(DiscriminatorZZ, self).__init__()\n",
        "\n",
        "        # If spectral normalization is desired, wrap the linear layers with it.\n",
        "        sn = torch.nn.utils.spectral_norm if do_spectral_norm else lambda x: x\n",
        "\n",
        "        # First layer: input dimension is latent_dim * 2 due to concatenation of z and rec_z.\n",
        "        self.fc1 = sn(nn.Linear(latent_dim * 2, 64))\n",
        "        # Second layer.\n",
        "        self.fc2 = sn(nn.Linear(64, 32))\n",
        "        # Third (output) layer: produces logits.\n",
        "        self.fc3 = sn(nn.Linear(32, 1))\n",
        "        # Dropout layer with rate 0.2.\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "        # Xavier initialization (Glorot Uniform)\n",
        "        nn.init.xavier_uniform_(self.fc1.weight)\n",
        "        nn.init.xavier_uniform_(self.fc2.weight)\n",
        "        nn.init.xavier_uniform_(self.fc3.weight)\n",
        "\n",
        "    def forward(self, z, rec_z):\n",
        "        # Concatenate along the feature dimension.\n",
        "        net = torch.cat([z, rec_z], dim=1)\n",
        "\n",
        "        # Layer 1: Dense -> Leaky ReLU -> Dropout.\n",
        "        net = F.leaky_relu(self.fc1(net),negative_slope=0.2)\n",
        "        net = self.dropout(net)  # Dropout is active only in training mode.\n",
        "\n",
        "        # Layer 2: Dense -> Leaky ReLU -> Dropout.\n",
        "        net = F.leaky_relu(self.fc2(net),negative_slope=0.2)\n",
        "        net = self.dropout(net)\n",
        "\n",
        "        # Save intermediate layer for feature matching.\n",
        "        intermediate_layer = net\n",
        "\n",
        "        # Layer 3: Dense to produce logits (no activation).\n",
        "        logits = self.fc3(net)\n",
        "        return logits, intermediate_layer\n",
        "\n"
      ],
      "metadata": {
        "id": "1ov8dIw95bJW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "# Training Loop\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Hyperparameters\n",
        "input_dim = X_normal.shape[1]\n",
        "learning_rate_gen = 1e-3   # Generator (Encoder)\n",
        "learning_rate_disc_xx = 2e-4 # Discriminator (lower than encoder)\n",
        "learning_rate_enc = 1e-3\n",
        "learning_rate_disc_xz = 1e-6\n",
        "learning_rate_disc_zz = 1e-6\n",
        "latent_dim = 64\n",
        "x_dim = input_dim\n",
        "num_epochs = 50\n",
        "log_interval = 100\n",
        "lambda_cycle = 1.0\n",
        "\n",
        "# Loss function\n",
        "criterion_s = nn.BCEWithLogitsLoss(reduction='sum')\n",
        "criterion_m = nn.BCEWithLogitsLoss(reduction='mean')\n",
        "criterion_n = nn.BCEWithLogitsLoss(reduction='none')\n",
        "\n",
        "# Move models to device (GPU if available)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Initialize networks (example constructors; adapt as needed)\n",
        "encoder = Encoder(x_dim, latent_dim).to(device)\n",
        "generator = Generator(latent_dim, x_dim).to(device)\n",
        "discriminator_xz = DiscriminatorXZ(x_dim, latent_dim,do_spectral_norm=True).to(device)\n",
        "discriminator_xx = DiscriminatorXX(x_dim,do_spectral_norm=True).to(device)\n",
        "discriminator_zz = DiscriminatorZZ(latent_dim,do_spectral_norm=True).to(device)\n",
        "\n",
        "\n",
        "# Optimizers\n",
        "optimizer_D_xz = optim.Adam(discriminator_xz.parameters(), lr=learning_rate_disc_xz, betas=(0.5, 0.9))\n",
        "optimizer_D_xx = optim.Adam(discriminator_xx.parameters(), lr=learning_rate_disc_xx, betas=(0.5, 0.9))\n",
        "optimizer_D_zz = optim.Adam(discriminator_zz.parameters(), lr=learning_rate_disc_zz, betas=(0.5, 0.9))\n",
        "\n",
        "# Separate optimizers for generator and encoder\n",
        "optimizer_G = optim.Adam(generator.parameters(), lr=learning_rate_gen, betas=(0.5, 0.9))\n",
        "optimizer_E = optim.Adam(encoder.parameters(), lr=learning_rate_enc, betas=(0.5, 0.9))\n",
        "\n",
        "# Define a clipping value (adjust as needed)\n",
        "discriminator_update_interval=2\n",
        "# recon_criterion = torch.nn.L1Loss()\n",
        "\n",
        "torch.autograd.set_detect_anomaly(True)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    encoder.train()\n",
        "    generator.train()\n",
        "    discriminator_xz.train()\n",
        "    discriminator_xx.train()\n",
        "    discriminator_zz.train()\n",
        "\n",
        "    # For logging losses per epoch (average per sample)\n",
        "    total_loss_D_xz = 0.0\n",
        "    total_loss_D_xx = 0.0\n",
        "    total_loss_D_zz = 0.0\n",
        "    total_loss_G = 0.0\n",
        "    total_loss_E = 0.0\n",
        "    n_batches = 0\n",
        "\n",
        "    for i, real_x in enumerate(train_loader):\n",
        "        # real_x = real_x.to(device)\n",
        "        real_x = real_x.type(torch.FloatTensor).to(device)\n",
        "        # real_x.requires_grad = True\n",
        "        batch_size = real_x.size(0)\n",
        "        current_batch_size = batch_size\n",
        "        n_batches += 1\n",
        "\n",
        "        # Define labels (adapted: real=0, fake=1)\n",
        "        # real_labels = torch.ones(batch_size, 1, device=device)\n",
        "        # fake_labels = torch.zeros(batch_size, 1, device=device)\n",
        "\n",
        "        real_labels = torch.full((batch_size, 1), 0.9, device=device)  # Use 0.9 instead of 1\n",
        "        fake_labels = torch.full((batch_size, 1), 0.1, device=device)  # Use 0.1 instead of 0\n",
        "\n",
        "        if i % discriminator_update_interval == 0:\n",
        "            # ============================\n",
        "            # 1. Update Discriminator_xz\n",
        "            # ============================\n",
        "            optimizer_D_xz.zero_grad()\n",
        "\n",
        "            # Real pairs: (x, encoder(x))\n",
        "            z_enc = encoder(real_x)\n",
        "            logits_real_xz, _ = discriminator_xz(real_x, z_enc)\n",
        "            loss_real_xz = criterion_m(logits_real_xz, real_labels)\n",
        "\n",
        "            # Fake pairs: (generator(z_noise), z_noise)\n",
        "            z_noise = torch.randn(batch_size, latent_dim, device=device)\n",
        "            x_fake = generator(z_noise)\n",
        "            logits_fake_xz, _ = discriminator_xz(x_fake, z_noise)\n",
        "            loss_fake_xz = criterion_m(logits_fake_xz, fake_labels)\n",
        "\n",
        "            loss_D_xz = (loss_real_xz + loss_fake_xz).clone() #(loss_real_xz + loss_fake_xz) / 2\n",
        "            loss_D_xz.backward()\n",
        "            optimizer_D_xz.step()\n",
        "\n",
        "            # ============================\n",
        "            # 2. Update Discriminator_xx\n",
        "            # ============================\n",
        "            optimizer_D_xx.zero_grad()\n",
        "\n",
        "            # Real pairs: (x, x)\n",
        "            logits_real_xx, _ = discriminator_xx(real_x, real_x)\n",
        "            loss_real_xx = criterion_s(logits_real_xx, real_labels)\n",
        "\n",
        "            # Fake pairs: (x, generator(encoder(x)))\n",
        "            x_rec = generator(encoder(real_x))\n",
        "            logits_fake_xx, _ = discriminator_xx(real_x, x_rec)\n",
        "            loss_fake_xx = criterion_s(logits_fake_xx, fake_labels)\n",
        "\n",
        "            loss_D_xx = torch.mean(loss_real_xx + loss_fake_xx).clone()  #(loss_real_xx + loss_fake_xx) / 2\n",
        "            loss_D_xx.backward()\n",
        "            optimizer_D_xx.step()\n",
        "\n",
        "            # ============================\n",
        "            # 3. Update Discriminator_zz\n",
        "            # ============================\n",
        "            optimizer_D_zz.zero_grad()\n",
        "\n",
        "            # Real pairs: (z, z) where z is sampled from the prior (noise)\n",
        "            z_prior = torch.randn(batch_size, latent_dim, device=device)\n",
        "            logits_real_zz, _ = discriminator_zz(z_prior, z_prior)\n",
        "            loss_real_zz = criterion_n(logits_real_zz, real_labels)\n",
        "\n",
        "            # Fake pairs: (z, encoder(generator(z)))\n",
        "            x_fake = generator(z_prior)\n",
        "            z_rec = encoder(x_fake).detach()\n",
        "            logits_fake_zz, _ = discriminator_zz(z_prior, z_rec)\n",
        "            loss_fake_zz = criterion_n(logits_fake_zz, fake_labels)\n",
        "\n",
        "            loss_D_zz = torch.mean(loss_real_zz + loss_fake_zz)#(loss_real_zz + loss_fake_zz) / 2\n",
        "            loss_D_zz.backward()\n",
        "            optimizer_D_zz.step()\n",
        "\n",
        "        #### GEN Code\n",
        "\n",
        "\n",
        "        z_noise = torch.randn(batch_size, latent_dim, device=device)\n",
        "        x_fake = generator(z_noise)\n",
        "        l_generator, _ = discriminator_xz(x_fake, z_noise)\n",
        "        # Adversarial loss for the generator: now we use real label = 0 (instead of 1)\n",
        "        gen_loss_xz = criterion_m(l_generator, torch.ones_like(l_generator))\n",
        "\n",
        "        real_x_clone = real_x.clone()\n",
        "\n",
        "        # Cycle consistency loss for the x branch:\n",
        "        # For real x (should be classified as real, i.e., 0)\n",
        "\n",
        "        x_real_dis, _ = discriminator_xx(real_x_clone, real_x_clone)\n",
        "\n",
        "        # # Fake pairs: (x, generator(encoder(x)))\n",
        "        x_real_gen = criterion_s(x_real_dis, torch.zeros_like(x_real_dis))\n",
        "\n",
        "        x_rec = generator(encoder(real_x_clone))\n",
        "        x_fake_dis, _ = discriminator_xx(real_x_clone, x_rec)\n",
        "\n",
        "        # For fake (reconstructed) x (should be classified as fake, i.e., 1)\n",
        "        x_fake_gen = criterion_s(x_fake_dis, torch.ones_like(x_fake_dis))\n",
        "\n",
        "        cost_x = torch.mean(x_real_gen + x_fake_gen).clone()\n",
        "\n",
        "         # # Real pairs: (z, z) where z is sampled from the prior (noise)\n",
        "        z_prior = torch.randn(batch_size, latent_dim, device=device)\n",
        "        z_real_dis, _ = discriminator_zz(z_prior, z_prior)\n",
        "\n",
        "        # # Fake pairs: (z, encoder(generator(z)))\n",
        "        x_fake = generator(z_prior)\n",
        "        z_rec = encoder(x_fake)\n",
        "        z_fake_dis, _ = discriminator_zz(z_prior, z_rec)\n",
        "\n",
        "\n",
        "        z_real_gen = criterion_n(z_real_dis, torch.zeros_like(z_real_dis))\n",
        "        z_fake_gen = criterion_n(z_fake_dis, torch.ones_like(z_fake_dis))\n",
        "        cost_z = torch.mean(z_real_gen + z_fake_gen)\n",
        "\n",
        "        loss_generator = (gen_loss_xz + lambda_cycle * (cost_x + cost_z)).clone()\n",
        "        optimizer_G.zero_grad()\n",
        "        loss_generator.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "\n",
        "        # # Cycle consistency loss for the z branch:\n",
        "\n",
        "        # # # Real pairs: (z, z) where z is sampled from the prior (noise)\n",
        "        # z_prior = torch.randn(batch_size, latent_dim, device=device)\n",
        "        # z_real_dis, _ = discriminator_zz(z_prior, z_prior)\n",
        "\n",
        "        # # # Fake pairs: (z, encoder(generator(z)))\n",
        "        # x_fake = generator(z_prior)\n",
        "        # z_rec = encoder(x_fake)\n",
        "        # z_fake_dis, _ = discriminator_zz(z_prior, z_rec)\n",
        "\n",
        "\n",
        "        # z_real_gen = criterion_n(z_real_dis, torch.zeros_like(z_real_dis))\n",
        "        # z_fake_gen = criterion_n(z_fake_dis, torch.ones_like(z_fake_dis))\n",
        "        # cost_z = torch.mean(z_real_gen + z_fake_gen)\n",
        "\n",
        "\n",
        "        # Total cycle-consistency loss: include z branch if allowed\n",
        "        # cycle_consistency_loss = cost_x + cost_z\n",
        "        # cycle_consistency_loss = cost_x.clone()\n",
        "\n",
        "\n",
        "        # Final losses:\n",
        "\n",
        "        # For the encoder, we use the loss computed from discriminator_xz.\n",
        "        l_encoder, _ = discriminator_xz(real_x_clone, encoder(real_x_clone))\n",
        "        # Adversarial loss for the generator: now we use real label = 0 (instead of 1)\n",
        "        enc_loss_xz = criterion_m(l_encoder, torch.zeros_like(l_encoder))\n",
        "\n",
        "        x_real_dis, _ = discriminator_xx(real_x_clone, real_x_clone)\n",
        "        x_real_gen = criterion_s(x_real_dis, torch.zeros_like(x_real_dis))\n",
        "\n",
        "        # # Fake pairs: (x, generator(encoder(x)))\n",
        "        x_rec = generator(encoder(real_x_clone))\n",
        "        x_fake_dis, _ = discriminator_xx(real_x_clone, x_rec)\n",
        "\n",
        "\n",
        "        # For fake (reconstructed) x (should be classified as fake, i.e., 1)\n",
        "        x_fake_gen = criterion_s(x_fake_dis, torch.ones_like(x_fake_dis))\n",
        "\n",
        "        cost_x = torch.mean(x_real_gen + x_fake_gen).clone()\n",
        "\n",
        "        # # Real pairs: (z, z) where z is sampled from the prior (noise)\n",
        "        z_prior = torch.randn(batch_size, latent_dim, device=device)\n",
        "        z_real_dis, _ = discriminator_zz(z_prior, z_prior)\n",
        "\n",
        "        # # Fake pairs: (z, encoder(generator(z)))\n",
        "        x_fake = generator(z_prior)\n",
        "        z_rec = encoder(x_fake)\n",
        "        z_fake_dis, _ = discriminator_zz(z_prior, z_rec)\n",
        "\n",
        "\n",
        "        z_real_gen = criterion_n(z_real_dis, torch.zeros_like(z_real_dis))\n",
        "        z_fake_gen = criterion_n(z_fake_dis, torch.ones_like(z_fake_dis))\n",
        "        cost_z = torch.mean(z_real_gen + z_fake_gen)\n",
        "\n",
        "        loss_encoder = (enc_loss_xz + lambda_cycle * (cost_x + cost_z)).clone()\n",
        "        optimizer_E.zero_grad()\n",
        "        loss_encoder.backward()  # No retain_graph needed, last step\n",
        "        optimizer_E.step()\n",
        "\n",
        "\n",
        "\n",
        "        # Log per-iteration (average loss per sample)\n",
        "        total_loss_D_xz += loss_D_xz.item() / current_batch_size if i % discriminator_update_interval == 0 else 0\n",
        "        total_loss_D_xx += loss_D_xx.item() / current_batch_size if i % discriminator_update_interval == 0 else 0\n",
        "        total_loss_D_zz += loss_D_zz.item() / current_batch_size if i % discriminator_update_interval == 0 else 0\n",
        "        total_loss_G    += loss_generator.item() / current_batch_size\n",
        "        total_loss_E    += loss_encoder.item() / current_batch_size\n",
        "\n",
        "\n",
        "    # End of epoch: compute and log average losses for discriminators (if updated)\n",
        "    num_disc_updates = (n_batches // discriminator_update_interval) or 1\n",
        "    avg_loss_D_xz = total_loss_D_xz / num_disc_updates\n",
        "    avg_loss_D_xx = total_loss_D_xx / num_disc_updates\n",
        "    avg_loss_D_zz = total_loss_D_zz / num_disc_updates\n",
        "    avg_loss_G = total_loss_G / n_batches\n",
        "    avg_loss_E = total_loss_E / n_batches\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}] Summary:\")\n",
        "    print(f\"  Average Loss_D_xz: {avg_loss_D_xz:.4f}  Average Loss_D_xx: {avg_loss_D_xx:.4f} Average Loss_D_zz: {avg_loss_D_zz:.4f}\")\n",
        "    # print(f\"  Average Loss_D_xz: {avg_loss_D_xz:.4f}  Average Loss_D_xx: {avg_loss_D_xx:.4f}\")\n",
        "    print(f\"  Average Loss_G: {avg_loss_G:.4f}, Average Loss_E: {avg_loss_E:.4f}\")\n",
        "\n",
        "print(\"Training Complete!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kH9NUBb_iK3e",
        "outputId": "74f3b41b-b1b3-4e64-e785-d307337dbf72"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50] Summary:\n",
            "  Average Loss_D_xz: 2.7371  Average Loss_D_xx: 13670.4392 Average Loss_D_zz: 0.0013\n",
            "  Average Loss_G: 549.5845, Average Loss_E: 542.3077\n",
            "Epoch [2/50] Summary:\n",
            "  Average Loss_D_xz: 5.4525  Average Loss_D_xx: 11054.9384 Average Loss_D_zz: 0.0022\n",
            "  Average Loss_G: 43.1460, Average Loss_E: 39.6273\n",
            "Epoch [3/50] Summary:\n",
            "  Average Loss_D_xz: 4.2775  Average Loss_D_xx: 3298.4888 Average Loss_D_zz: 0.0018\n",
            "  Average Loss_G: 187.5992, Average Loss_E: 118.4719\n",
            "Epoch [4/50] Summary:\n",
            "  Average Loss_D_xz: 3.4734  Average Loss_D_xx: 685.2099 Average Loss_D_zz: 0.0021\n",
            "  Average Loss_G: 329.0814, Average Loss_E: 218.0547\n",
            "Epoch [5/50] Summary:\n",
            "  Average Loss_D_xz: 1.4424  Average Loss_D_xx: 128.6648 Average Loss_D_zz: 0.0018\n",
            "  Average Loss_G: 140.5616, Average Loss_E: 116.2702\n",
            "Epoch [6/50] Summary:\n",
            "  Average Loss_D_xz: 1.1222  Average Loss_D_xx: 39.7489 Average Loss_D_zz: 0.0021\n",
            "  Average Loss_G: 60.8459, Average Loss_E: 52.8149\n",
            "Epoch [7/50] Summary:\n",
            "  Average Loss_D_xz: 1.1237  Average Loss_D_xx: 19.3142 Average Loss_D_zz: 0.0019\n",
            "  Average Loss_G: 43.7234, Average Loss_E: 34.7057\n",
            "Epoch [8/50] Summary:\n",
            "  Average Loss_D_xz: 0.6245  Average Loss_D_xx: 11.0077 Average Loss_D_zz: 0.0022\n",
            "  Average Loss_G: 31.3645, Average Loss_E: 23.7405\n",
            "Epoch [9/50] Summary:\n",
            "  Average Loss_D_xz: 0.3977  Average Loss_D_xx: 6.1811 Average Loss_D_zz: 0.0020\n",
            "  Average Loss_G: 24.4260, Average Loss_E: 18.8681\n",
            "Epoch [10/50] Summary:\n",
            "  Average Loss_D_xz: 0.3460  Average Loss_D_xx: 3.9087 Average Loss_D_zz: 0.0020\n",
            "  Average Loss_G: 21.3185, Average Loss_E: 15.8981\n",
            "Epoch [11/50] Summary:\n",
            "  Average Loss_D_xz: 0.5167  Average Loss_D_xx: 2.8328 Average Loss_D_zz: 0.0023\n",
            "  Average Loss_G: 16.4066, Average Loss_E: 13.8546\n",
            "Epoch [12/50] Summary:\n",
            "  Average Loss_D_xz: 0.7174  Average Loss_D_xx: 2.4893 Average Loss_D_zz: 0.0022\n",
            "  Average Loss_G: 13.6992, Average Loss_E: 11.1118\n",
            "Epoch [13/50] Summary:\n",
            "  Average Loss_D_xz: 0.8031  Average Loss_D_xx: 1.9146 Average Loss_D_zz: 0.0024\n",
            "  Average Loss_G: 11.7538, Average Loss_E: 10.0912\n",
            "Epoch [14/50] Summary:\n",
            "  Average Loss_D_xz: 0.7776  Average Loss_D_xx: 1.8646 Average Loss_D_zz: 0.0023\n",
            "  Average Loss_G: 10.0764, Average Loss_E: 8.2786\n",
            "Epoch [15/50] Summary:\n",
            "  Average Loss_D_xz: 0.7455  Average Loss_D_xx: 1.4932 Average Loss_D_zz: 0.0030\n",
            "  Average Loss_G: 8.4788, Average Loss_E: 7.1485\n",
            "Epoch [16/50] Summary:\n",
            "  Average Loss_D_xz: 0.8430  Average Loss_D_xx: 1.3603 Average Loss_D_zz: 0.0029\n",
            "  Average Loss_G: 7.2364, Average Loss_E: 6.4734\n",
            "Epoch [17/50] Summary:\n",
            "  Average Loss_D_xz: 0.6673  Average Loss_D_xx: 1.3215 Average Loss_D_zz: 0.0034\n",
            "  Average Loss_G: 7.1042, Average Loss_E: 6.3475\n",
            "Epoch [18/50] Summary:\n",
            "  Average Loss_D_xz: 1.0919  Average Loss_D_xx: 1.2553 Average Loss_D_zz: 0.0034\n",
            "  Average Loss_G: 6.4056, Average Loss_E: 6.0087\n",
            "Epoch [19/50] Summary:\n",
            "  Average Loss_D_xz: 0.8149  Average Loss_D_xx: 1.3560 Average Loss_D_zz: 0.0029\n",
            "  Average Loss_G: 7.7765, Average Loss_E: 6.7097\n",
            "Epoch [20/50] Summary:\n",
            "  Average Loss_D_xz: 0.3380  Average Loss_D_xx: 1.2276 Average Loss_D_zz: 0.0028\n",
            "  Average Loss_G: 6.0625, Average Loss_E: 4.7684\n",
            "Epoch [21/50] Summary:\n",
            "  Average Loss_D_xz: 0.2140  Average Loss_D_xx: 1.1557 Average Loss_D_zz: 0.0029\n",
            "  Average Loss_G: 5.4490, Average Loss_E: 4.3591\n",
            "Epoch [22/50] Summary:\n",
            "  Average Loss_D_xz: 0.6121  Average Loss_D_xx: 1.1546 Average Loss_D_zz: 0.0028\n",
            "  Average Loss_G: 5.2315, Average Loss_E: 4.7794\n",
            "Epoch [23/50] Summary:\n",
            "  Average Loss_D_xz: 0.2429  Average Loss_D_xx: 1.0353 Average Loss_D_zz: 0.0032\n",
            "  Average Loss_G: 4.8229, Average Loss_E: 3.9876\n",
            "Epoch [24/50] Summary:\n",
            "  Average Loss_D_xz: 0.1941  Average Loss_D_xx: 1.0805 Average Loss_D_zz: 0.0031\n",
            "  Average Loss_G: 5.0937, Average Loss_E: 4.1350\n",
            "Epoch [25/50] Summary:\n",
            "  Average Loss_D_xz: 0.3741  Average Loss_D_xx: 1.0136 Average Loss_D_zz: 0.0034\n",
            "  Average Loss_G: 4.6031, Average Loss_E: 4.0792\n",
            "Epoch [26/50] Summary:\n",
            "  Average Loss_D_xz: 0.7319  Average Loss_D_xx: 1.1037 Average Loss_D_zz: 0.0038\n",
            "  Average Loss_G: 5.7648, Average Loss_E: 5.1251\n",
            "Epoch [27/50] Summary:\n",
            "  Average Loss_D_xz: 0.3209  Average Loss_D_xx: 1.0568 Average Loss_D_zz: 0.0031\n",
            "  Average Loss_G: 5.5516, Average Loss_E: 5.4818\n",
            "Epoch [28/50] Summary:\n",
            "  Average Loss_D_xz: 0.6722  Average Loss_D_xx: 1.0926 Average Loss_D_zz: 0.0038\n",
            "  Average Loss_G: 5.5370, Average Loss_E: 5.2842\n",
            "Epoch [29/50] Summary:\n",
            "  Average Loss_D_xz: 0.1449  Average Loss_D_xx: 1.0239 Average Loss_D_zz: 0.0036\n",
            "  Average Loss_G: 4.2194, Average Loss_E: 3.4699\n",
            "Epoch [30/50] Summary:\n",
            "  Average Loss_D_xz: 0.1338  Average Loss_D_xx: 0.9680 Average Loss_D_zz: 0.0037\n",
            "  Average Loss_G: 4.5352, Average Loss_E: 3.6126\n",
            "Epoch [31/50] Summary:\n",
            "  Average Loss_D_xz: 0.1748  Average Loss_D_xx: 1.0010 Average Loss_D_zz: 0.0041\n",
            "  Average Loss_G: 4.5260, Average Loss_E: 3.6458\n",
            "Epoch [32/50] Summary:\n",
            "  Average Loss_D_xz: 0.1817  Average Loss_D_xx: 0.9867 Average Loss_D_zz: 0.0040\n",
            "  Average Loss_G: 4.9608, Average Loss_E: 4.1653\n",
            "Epoch [33/50] Summary:\n",
            "  Average Loss_D_xz: 0.2808  Average Loss_D_xx: 1.0014 Average Loss_D_zz: 0.0044\n",
            "  Average Loss_G: 4.4067, Average Loss_E: 3.9670\n",
            "Epoch [34/50] Summary:\n",
            "  Average Loss_D_xz: 0.0930  Average Loss_D_xx: 0.9874 Average Loss_D_zz: 0.0042\n",
            "  Average Loss_G: 4.1525, Average Loss_E: 3.3149\n",
            "Epoch [35/50] Summary:\n",
            "  Average Loss_D_xz: 0.1113  Average Loss_D_xx: 0.9523 Average Loss_D_zz: 0.0036\n",
            "  Average Loss_G: 4.6896, Average Loss_E: 3.7624\n",
            "Epoch [36/50] Summary:\n",
            "  Average Loss_D_xz: 0.0941  Average Loss_D_xx: 0.9937 Average Loss_D_zz: 0.0040\n",
            "  Average Loss_G: 4.4907, Average Loss_E: 3.6641\n",
            "Epoch [37/50] Summary:\n",
            "  Average Loss_D_xz: 0.1506  Average Loss_D_xx: 0.9635 Average Loss_D_zz: 0.0040\n",
            "  Average Loss_G: 4.5272, Average Loss_E: 3.8389\n",
            "Epoch [38/50] Summary:\n",
            "  Average Loss_D_xz: 0.3408  Average Loss_D_xx: 1.0334 Average Loss_D_zz: 0.0037\n",
            "  Average Loss_G: 5.4377, Average Loss_E: 4.7275\n",
            "Epoch [39/50] Summary:\n",
            "  Average Loss_D_xz: 0.4010  Average Loss_D_xx: 0.9309 Average Loss_D_zz: 0.0040\n",
            "  Average Loss_G: 4.2077, Average Loss_E: 3.8424\n",
            "Epoch [40/50] Summary:\n",
            "  Average Loss_D_xz: 0.2286  Average Loss_D_xx: 0.9814 Average Loss_D_zz: 0.0038\n",
            "  Average Loss_G: 4.7168, Average Loss_E: 4.6268\n",
            "Epoch [41/50] Summary:\n",
            "  Average Loss_D_xz: 0.2656  Average Loss_D_xx: 0.9583 Average Loss_D_zz: 0.0043\n",
            "  Average Loss_G: 5.1982, Average Loss_E: 5.1699\n",
            "Epoch [42/50] Summary:\n",
            "  Average Loss_D_xz: 0.2785  Average Loss_D_xx: 0.9107 Average Loss_D_zz: 0.0038\n",
            "  Average Loss_G: 4.5671, Average Loss_E: 4.2812\n",
            "Epoch [43/50] Summary:\n",
            "  Average Loss_D_xz: 0.2428  Average Loss_D_xx: 0.9288 Average Loss_D_zz: 0.0043\n",
            "  Average Loss_G: 4.2714, Average Loss_E: 3.8298\n",
            "Epoch [44/50] Summary:\n",
            "  Average Loss_D_xz: 0.3060  Average Loss_D_xx: 0.8971 Average Loss_D_zz: 0.0039\n",
            "  Average Loss_G: 4.5826, Average Loss_E: 4.0950\n",
            "Epoch [45/50] Summary:\n",
            "  Average Loss_D_xz: 0.1010  Average Loss_D_xx: 0.9302 Average Loss_D_zz: 0.0042\n",
            "  Average Loss_G: 3.9549, Average Loss_E: 3.3099\n",
            "Epoch [46/50] Summary:\n",
            "  Average Loss_D_xz: 0.1882  Average Loss_D_xx: 0.9035 Average Loss_D_zz: 0.0043\n",
            "  Average Loss_G: 4.3475, Average Loss_E: 4.0969\n",
            "Epoch [47/50] Summary:\n",
            "  Average Loss_D_xz: 0.1854  Average Loss_D_xx: 0.9345 Average Loss_D_zz: 0.0043\n",
            "  Average Loss_G: 4.7852, Average Loss_E: 5.0281\n",
            "Epoch [48/50] Summary:\n",
            "  Average Loss_D_xz: 0.2092  Average Loss_D_xx: 0.9525 Average Loss_D_zz: 0.0046\n",
            "  Average Loss_G: 4.4276, Average Loss_E: 3.8072\n",
            "Epoch [49/50] Summary:\n",
            "  Average Loss_D_xz: 0.1462  Average Loss_D_xx: 0.9063 Average Loss_D_zz: 0.0041\n",
            "  Average Loss_G: 4.3962, Average Loss_E: 3.9108\n",
            "Epoch [50/50] Summary:\n",
            "  Average Loss_D_xz: 0.1376  Average Loss_D_xx: 0.9246 Average Loss_D_zz: 0.0043\n",
            "  Average Loss_G: 4.3451, Average Loss_E: 4.5107\n",
            "Training Complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# --- Sampling ---\n",
        "num_samples_normal = X_normal.shape[0]\n",
        "num_samples_anomaly = X_anomaly.shape[0]\n",
        "# Sample from your normal and anomaly DataFrames (assume these are defined)\n",
        "# X_test_normal_sampled = X_test_normal.sample(n=num_samples_normal, random_state=42)\n",
        "# X_anomaly_sampled = X_anomaly.sample(n=num_samples_anomaly, random_state=42)\n",
        "# X_test_normal_sampled = X_normal\n",
        "# X_anomaly_sampled = X_anomaly\n",
        "# X_anomaly_sampled = X_test_normal_sampled\n",
        "\n",
        "# Create combined test dataset and labels\n",
        "X_test = pd.concat([X_normal, X_anomaly])\n",
        "y_test = np.concatenate([np.zeros(num_samples_normal, dtype=int),\n",
        "                         np.ones(num_samples_anomaly, dtype=int)])\n",
        "\n",
        "# --- Shuffling ---\n",
        "# Shuffle the rows of X_test and y_test together\n",
        "# shuffled_indices = np.random.permutation(X_test.index)\n",
        "# X_test_shuffled = X_test.loc[shuffled_indices]\n",
        "# y_test_shuffled = y_test[np.argsort(shuffled_indices)]  # This works if shuffled_indices is sorted;\n",
        "# Alternatively, we can use:\n",
        "# y_test_shuffled = y_test[list(shuffled_indices)]\n",
        "\n",
        "# --- Conversion to Tensors ---\n",
        "# Convert the shuffled DataFrame and labels to torch tensors\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "test_x_tensor = torch.tensor(X_test.values, dtype=torch.float32).to(device)\n",
        "test_y_tensor = torch.tensor(y_test, dtype=torch.long).to(device)\n",
        "\n",
        "# Create a TensorDataset and DataLoader\n",
        "test_dataset = TensorDataset(test_x_tensor, test_y_tensor)\n",
        "batch_size = 4096  # Adjust as needed\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Check the shapes\n",
        "print(\"Test X tensor shape:\", test_x_tensor.shape)\n",
        "print(\"Test Y tensor shape:\", test_y_tensor.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_REpzaxyF-Qe",
        "outputId": "38c3b2d8-e757-48cd-cbda-4d1013d939e5"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test X tensor shape: torch.Size([590540, 250])\n",
            "Test Y tensor shape: torch.Size([590540])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import numpy as np\n",
        "from sklearn.metrics import average_precision_score\n",
        "\n",
        "encoder.eval()\n",
        "generator.eval()\n",
        "discriminator_xx.eval()\n",
        "\n",
        "anomaly_scores = []\n",
        "y_true = []\n",
        "inference_times = []\n",
        "\n",
        "def compute_anomaly_score_combined(cnn_codes_orig, cnn_codes_rec, alpha=0.5):\n",
        "    \"\"\"\n",
        "    Computes the anomaly score as a weighted combination of the L1 and L2 norms.\n",
        "    alpha: weight for L1 loss (between 0 and 1). (1-alpha) is the weight for L2 loss.\n",
        "    \"\"\"\n",
        "    l1_score = torch.mean(torch.abs(cnn_codes_orig - cnn_codes_rec), dim=1)\n",
        "    l2_score = torch.norm(cnn_codes_orig - cnn_codes_rec, p=2, dim=1)\n",
        "    # Combine the scores.\n",
        "    combined_score = alpha * l1_score + (1 - alpha) * l2_score\n",
        "    return combined_score\n",
        "\n",
        "with torch.no_grad():\n",
        "    for x_batch, labels in test_loader:\n",
        "        x_batch = x_batch.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        # 1. Get CNN codes for original samples from Dxx.\n",
        "        #    Here, we assume model_Dxx(x) returns (logits, cnn_code)\n",
        "        _, cnn_codes_orig = discriminator_xx(x_batch,x_batch)\n",
        "\n",
        "        # 2. Compute reconstruction x_rec = G(E(x))\n",
        "        z = encoder(x_batch)\n",
        "        x_rec = generator(z)\n",
        "\n",
        "        # 3. Get CNN codes for reconstructed samples.\n",
        "        _, cnn_codes_rec = discriminator_xx(x_rec,x_rec)\n",
        "\n",
        "        # 4. Compute the L1 reconstruction error in the feature space (per sample).\n",
        "        #    Using mean absolute error (you could also use sum).\n",
        "        # batch_scores = torch.mean(torch.abs(cnn_codes_orig - cnn_codes_rec), dim=1)\n",
        "        # batch_scores = torch.norm(cnn_codes_orig - cnn_codes_rec, p=2, dim=1)\n",
        "        batch_scores = compute_anomaly_score_combined(cnn_codes_orig,cnn_codes_rec,alpha=0.5)\n",
        "\n",
        "        anomaly_scores.extend(batch_scores.cpu().numpy().tolist())\n",
        "        y_true.extend(labels.cpu().numpy().tolist())\n",
        "        # Record and store the inference time for this batch.\n",
        "        batch_inference_time = time.time() - start_time\n",
        "        inference_times.append(batch_inference_time)\n",
        "\n",
        "print(\"y_true: {}\".format(y_true[:5]))\n",
        "print(\"anomaly_scores: {}\".format(anomaly_scores[:5])) # Access the first element of the desired rows using slicing\n",
        "\n",
        "# Compute AUROC using the anomaly scores.\n",
        "auroc = roc_auc_score(y_true, anomaly_scores)\n",
        "print(\"AUROC: {:.4f}\".format(auroc))\n",
        "\n",
        "# Calculate average inference time over all batches.\n",
        "mean_inference_time = np.mean(inference_times)\n",
        "print(\"Mean inference time per batch: {:.4f} sec\".format(mean_inference_time))\n",
        "\n",
        "# Assume y_true is a list/array of true labels (0 for normal, 1 for anomaly)\n",
        "# and anomaly_scores is a list/array of your model's anomaly scores\n",
        "average_precision = average_precision_score(y_true, anomaly_scores)\n",
        "print(\"Average Precision (AUPRC): {:.4f}\".format(average_precision))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMyxQkO3QNUc",
        "outputId": "8dd53b30-a3fd-43a3-b7bf-7457c64b830e"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_true: [0, 0, 0, 0, 0]\n",
            "anomaly_scores: [0.5784403681755066, 0.4878670573234558, 0.39517101645469666, 0.08183398097753525, 0.5680821537971497]\n",
            "AUROC: 0.5219\n",
            "Mean inference time per batch: 0.0033 sec\n",
            "Average Precision (AUPRC): 0.0365\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Suppose these are defined from your ALAD model inference:\n",
        "# y_true: true labels, e.g. np.array([...])\n",
        "# anomaly_scores: continuous anomaly scores, e.g. np.array([...])\n",
        "\n",
        "# Convert lists to numpy arrays if necessary.\n",
        "y_true = np.array(y_true)\n",
        "anomaly_scores = np.array(anomaly_scores)\n",
        "\n",
        "# Option 1: Determine threshold using the 95th percentile of normal samples.\n",
        "# (Assumes that normal samples are labeled 0.)\n",
        "normal_scores = anomaly_scores[y_true == 0]\n",
        "threshold = np.percentile(normal_scores, 90)\n",
        "print(\"Threshold based on 95th percentile of normal samples:\", threshold)\n",
        "\n",
        "# Option 2: Or set a manual threshold (uncomment below if needed).\n",
        "# threshold = 0.5\n",
        "\n",
        "# Generate binary predictions: predict fraud (1) if score > threshold, else normal (0)\n",
        "y_pred = (anomaly_scores > threshold).astype(int)\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(y_true, y_pred)\n",
        "recall = recall_score(y_true, y_pred)\n",
        "f1 = f1_score(y_true, y_pred)\n",
        "\n",
        "print(\"Precision: {:.4f}\".format(precision))\n",
        "print(\"Recall: {:.4f}\".format(recall))\n",
        "print(\"F1 Score: {:.4f}\".format(f1))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GK98vlyz5aaU",
        "outputId": "0506d7c5-48f8-4637-ad72-ac9dcb119a61"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Threshold based on 95th percentile of normal samples: 36.39354400634766\n",
            "Precision: 0.0375\n",
            "Recall: 0.1074\n",
            "F1 Score: 0.0556\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Assume y_true and anomaly_scores are NumPy arrays\n",
        "# where y_true==0 for normal and y_true==1 for anomalies.\n",
        "\n",
        "\n",
        "normal_scores = anomaly_scores[y_true == 0]\n",
        "anomaly_scores_only = anomaly_scores[y_true == 1]\n",
        "\n",
        "plt.hist(normal_scores, bins=50, alpha=0.6, label='Normal')\n",
        "plt.hist(anomaly_scores_only, bins=50, alpha=0.6, label='Anomaly')\n",
        "plt.xlabel(\"Anomaly Score\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.title(\"Distribution of Anomaly Scores\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "4PfQB52wCfsL",
        "outputId": "b2987914-b78d-4e2b-9701-d36c5dfc41ef"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import precision_recall_curve, auc, average_precision_score\n",
        "\n",
        "# Compute Precision-Recall curve\n",
        "precision, recall, _ = precision_recall_curve(y_true, anomaly_scores)\n",
        "\n",
        "# Compute AUPRC (Area Under PR Curve)\n",
        "auprc = auc(recall, precision)  # Using AUC function\n",
        "ap_score = average_precision_score(y_true, anomaly_scores)  # Direct AUPRC score\n",
        "\n",
        "print(f\"AUPRC (using auc function): {auprc:.4f}\")\n",
        "print(f\"AUPRC (using average_precision_score): {ap_score:.4f}\")\n",
        "\n",
        "# Plot Precision-Recall curve\n",
        "plt.figure(figsize=(6, 5))\n",
        "plt.plot(recall, precision, marker='.', label=f'AUPRC = {auprc:.4f}')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "id": "KtGYnSbuHTNe",
        "outputId": "78ab5f3a-b35b-483a-cfb5-7a3df955cfd9"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUPRC (using auc function): 0.0365\n",
            "AUPRC (using average_precision_score): 0.0365\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}